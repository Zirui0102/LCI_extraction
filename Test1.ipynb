{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d16817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "import PyPDF2\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from io import StringIO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6562a045",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "     api_key=os.environ.get(\"OPENAI_API_KEY\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8687d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1(df):\n",
    "    \"\"\"Model 1 will turn text in dataframe to a summarized reaction condition table.The dataframe should have a column \"file name\" and a column \"exp content\".\"\"\"\n",
    "    response_msgs = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        column1_value = row[df.columns[0]]\n",
    "        column2_value = row['content']\n",
    "\n",
    "        max_tokens = 3000\n",
    "        if count_tokens(column2_value) > max_tokens:\n",
    "            context_list = split_content(column2_value, max_tokens)\n",
    "        else:\n",
    "            context_list = [column2_value]\n",
    "\n",
    "        answers = ''  # Collect answers from chatGPT\n",
    "        for context in context_list:\n",
    "            print(\"Start to analyze paper \" + str(column1_value) )\n",
    "            user_heading = f\"This is an experimental section on MOF synthesis from paper {column1_value}\\n\\nContext:\\n{context}\"\n",
    "            user_ending = \"\"\"Q: Can you summarize the following details in a table: \n",
    "            compound name or chemical formula (if the name is not provided), metal source, metal amount, organic linker(s), \n",
    "            linker amount, modulator, modulator amount or volume, solvent(s), solvent volume(s), reaction temperature, \n",
    "            and reaction time? If any information is not provided or you are unsure, use \"N/A\". \n",
    "            Please focus on extracting experimental conditions from only the MOF synthesis and ignore information related to organic linker synthesis, \n",
    "            MOF postsynthetic modification, high throughput (HT) experiment details or catalysis reactions. \n",
    "            If multiple conditions are provided for the same compound, use multiple rows to represent them. If multiple units or components are provided for the same factor (e.g.  g and mol for the weight, multiple linker or metals, multiple temperature and reaction time, mixed solvents, etc), include them in the same cell and separate by comma.\n",
    "            The table should have 11 columns, all in lowercase:\n",
    "            | compound name | metal source | metal amount | linker | linker amount | modulator | modulator amount or volume | solvent | solvent volume | reaction temperature | reaction time |\n",
    "\n",
    "            A:\"\"\"   \n",
    "\n",
    "            attempts = 3\n",
    "            while attempts > 0:\n",
    "                try:\n",
    "                    response = client.chat.completions.create(\n",
    "                        model='gpt-3.5-turbo',\n",
    "                        messages=[{\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \"\"\"Answer the question as truthfully as possible using the provided context,\n",
    "                                        and if the answer is not contained within the text below, say \"N/A\" \"\"\"\n",
    "                        },\n",
    "                            {\"role\": \"user\", \"content\": user_heading + user_ending}]\n",
    "                    )\n",
    "                    answer_str = response.choices[0].message.content\n",
    "                    if not answer_str.lower().startswith(\"n/a\"):\n",
    "                        answers += '\\n' + answer_str\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    attempts -= 1\n",
    "                    if attempts <= 0:\n",
    "                        print(f\"Error: Failed to process paper {column1_value}. Skipping. (model 1)\")\n",
    "                        break\n",
    "                    print(f\"Error: {str(e)}. Retrying in 60 seconds. {attempts} attempts remaining. (model 1)\")\n",
    "                    time.sleep(60)\n",
    "\n",
    "        response_msgs.append(answers)\n",
    "    df = df.copy()\n",
    "    df.loc[:, 'summarized'] = response_msgs\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f2677f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_condition(df,column_name):\n",
    "    \"\"\"This function converts the text from a ChatGPT conversation into a DataFrame.\n",
    "    It also cleans the DataFrame by dropping additional headers and empty lines.    \"\"\"\n",
    "    \n",
    "    table_text = df[column_name].str.cat(sep='\\n')\n",
    "\n",
    "    # Remove leading and trailing whitespace\n",
    "    table_text = table_text.strip()\n",
    "    \n",
    "    # Split the table into rows\n",
    "    rows = table_text.split('\\n')\n",
    "\n",
    "    # Extract the header row and the divider row\n",
    "    header_row, divider_row, *data_rows = rows\n",
    "\n",
    "    # Extract column names from the header row\n",
    "\n",
    "    column_names = ['compound name', 'metal source', 'metal amount', 'linker', 'linker amount',\n",
    "                   'modulator', 'modulator amount or volume', 'solvent', 'solvent volume', 'reaction temperature',\n",
    "                   'reaction time']\n",
    "\n",
    "    # Create a list of dictionaries to store the table data\n",
    "    data = []\n",
    "\n",
    "    # Process each data row\n",
    "    for row in data_rows:\n",
    "\n",
    "        # Split the row into columns\n",
    "        columns = [col.strip() for col in row.split('|') if col.strip()]\n",
    "    \n",
    "        # Create a dictionary to store the row data\n",
    "        row_data = {col_name: col_value for col_name, col_value in zip(column_names, columns)}\n",
    "    \n",
    "        # Append the dictionary to the data list\n",
    "        data.append(row_data)\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    \n",
    "    \"\"\"Make df clean by drop additional header and empty lines \"\"\"\n",
    "    def contains_pattern(s, patterns):\n",
    "        return any(re.search(p, s) for p in patterns)\n",
    "\n",
    "    def drop_rows_with_patterns(df, column_name):\n",
    "        #empty cells, N/A cells and header cells\n",
    "        patterns = [r'^\\s*$', r'--',r'-\\s-', r'compound', r'Compound',r'Compound name', r'Compound Name',\n",
    "                r'NaN',r'N/A',r'n/a',r'\\nN/A', r'note', r'Note']\n",
    "        \n",
    "        mask = df[column_name].apply(lambda x: not contains_pattern(str(x), patterns))\n",
    "        filtered_df = df[mask]\n",
    "    \n",
    "        return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb8016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(text))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78b2126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_df = pd.read_csv(\"C:/Users/89751/OneDrive/桌面/228paper_info1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d1275d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file ID</th>\n",
       "      <th>file name short</th>\n",
       "      <th>doi</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>05acetylene</td>\n",
       "      <td>10.1038/nature03852</td>\n",
       "      <td>Synthesis of Cu2(pzdc)2(pyz)·2H2O (hydrated co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>05RodPackings</td>\n",
       "      <td>10.1021/ja045123o</td>\n",
       "      <td>\"Synthesis of Compounds. Zn3(OH)2(BPDC)2â(DEF)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file ID file name short                  doi  \\\n",
       "0        1     05acetylene  10.1038/nature03852   \n",
       "1        2   05RodPackings    10.1021/ja045123o   \n",
       "\n",
       "                                             content  \n",
       "0  Synthesis of Cu2(pzdc)2(pyz)·2H2O (hydrated co...  \n",
       "1  \"Synthesis of Compounds. Zn3(OH)2(BPDC)2â(DEF)...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7da6db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to analyze paper 1\n",
      "Start to analyze paper 2\n"
     ]
    }
   ],
   "source": [
    "model_1_table = tabulate_condition(model_1(syn_df),\"summarized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dd1f75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_1_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b13183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
